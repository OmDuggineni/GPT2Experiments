{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "GPT2 Grammar Correction(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro-tiQn95foI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3bda6744-20ad-4c21-cae0-af50498c0e5a"
      },
      "source": [
        "!rm -rv ./*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "removed './sample_data/anscombe.json'\n",
            "removed './sample_data/README.md'\n",
            "removed './sample_data/california_housing_test.csv'\n",
            "removed './sample_data/mnist_test.csv'\n",
            "removed './sample_data/california_housing_train.csv'\n",
            "removed './sample_data/mnist_train_small.csv'\n",
            "removed directory './sample_data'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeZqckZEhYMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "dae3fa66-4c91-4ccf-90ce-17ea999fa68a"
      },
      "source": [
        "#GPU info\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 14 10:57:01 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNRbJsGSlggs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#disable additional logs\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJaE0sYrHJ7n",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "f486417c-7d7b-4fe5-a63a-b0de6f63fb89"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install gpt-2-simple"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=9064c0b39d04307830aacbe63234f782a0d5b4959af55d37b890b61ed2cb108a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvM7AWkOHq39",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "f62ea5bc-e365-4048-a767-44ffb0d90bd8"
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "model_name = \"1558M\"\n",
        "\n",
        "#Downloads all GPT-2 models\n",
        "gpt2.download_gpt2(model_name=\"124M\")\n",
        "gpt2.download_gpt2(model_name=\"355M\")\n",
        "gpt2.download_gpt2(model_name=\"774M\")\n",
        "gpt2.download_gpt2(model_name=\"1558M\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 241Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 79.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 387Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:03, 141Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 464Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 162Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 186Mit/s]                                                       \n",
            "Fetching checkpoint: 1.05Mit [00:00, 525Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 105Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 827Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:18, 76.5Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 285Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 120Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 192Mit/s]                                                       \n",
            "Fetching checkpoint: 1.05Mit [00:00, 352Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 93.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 277Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:11, 43.3Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 427Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 215Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 242Mit/s]                                                       \n",
            "Fetching checkpoint: 1.05Mit [00:00, 708Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 137Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 784Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:35, 40.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 345Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 195Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 202Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH374VJvm8TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use 7zip to compress model files\n",
        "\n",
        "#!apt install p7zip\n",
        "#!7z a gpt-2-models.7z models/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4K6-KWW1zSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use rclone to copy model files to google drive\n",
        "#from subprocess import Popen, PIPE\n",
        "#import time;\n",
        "#\n",
        "#!umount ./gdrive\n",
        "#!apt install rclone\n",
        "#!rclone config\n",
        "#!rclone copy gpt-2-models.7z gdrive:/ --stats 1s --verbose"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPFSKeVDNrP",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kRGYqzmO5QcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c294501-6f09-4668-e025-ffe59c07e8d3"
      },
      "source": [
        "%%file prefix.txt\n",
        "Poor English: Please provide me with a short brief of the design you’re looking for and that’d be nice if you could share some examples or project you did before.\n",
        "Corrected English: Please provide me with a short brief of the design you’re looking for and some examples or previous projects you’ve done would be helpful.\n",
        "Poor English: If I’m stressed out about something, I tend to have problem to fall asleep.\n",
        "Corrected English: If I’m stressed out about something, I tend to have a problem falling asleep.\n",
        "Poor English: There is plenty of fun things to do in the summer when your able to go outside.\n",
        "Corrected English: There are plenty of fun things to do in the summer when you are able to go outside.\n",
        "Poor English: She no went to the market.\n",
        "Corrected English: She didn’t go to the market.\n",
        "Poor English: Thank you for picking me as your designer. I’d appreciate it.\n",
        "Corrected English: Thank you for picking me as your designer. I appreciate it.\n",
        "Poor English: I is a person.\n",
        "Corrected English: I am a person.\n",
        "Poor English: I used to done that.\n",
        "Corrected English: I used to do that."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing prefix.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHVhcSlg3apa",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "764e1a9c-daed-46fc-fbe1-9daa8a599082"
      },
      "source": [
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/1558M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/1558M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wtk37QtDUvj",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prefix = open('prefix.txt', 'r').read().rstrip('\\n');\n",
        "def grammar_correct(input):\n",
        "    global prefix, model_name;\n",
        "    full_prefix = prefix + \"\\n\" + \"Poor English: \" + input + \"\\nCorrected English: \";\n",
        "    return gpt2.generate(sess, model_name=model_name, prefix=full_prefix, include_prefix=False, length=20, temperature=0.9, top_p=0.9, return_as_list=True)[0].replace(full_prefix, \"\").split(\"\\n\")[0].split(\"<|endoftext|>\")[0].replace(\"Corrected English: \", \"\").strip().lstrip(\".\").lstrip(\",\").lstrip(\"'\").lstrip('\"');"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKE2yZmn1Fmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6623064b-2323-4048-ca26-15a8753257ae"
      },
      "source": [
        "print(grammar_correct(\"I used to swam in the ocean.\"));"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:32: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "ive used to swam in the ocean.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPItZsu1Fzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36710f34-b0bd-4e78-d4e2-238d72906d94"
      },
      "source": [
        "print(grammar_correct(\"She are a person.\"));"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She is a person.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MWg9qGzY2ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd2e533e-9548-4d09-c124-c7af39d0fbfa"
      },
      "source": [
        "print(grammar_correct(\"I swim wit the sharks.\"));"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I swim with the sharks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CG-nf2r1E5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(grammar_correct(input()));"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}